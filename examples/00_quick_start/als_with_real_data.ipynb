{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "from pyspark.sql.functions import col, count, when\n",
    "from pyspark.sql.functions import rand\n",
    "\n",
    "from pyspark.sql.functions import explode, col\n",
    "\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ALS Recommender\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load data\n",
    "file_path = 'interactions.csv'\n",
    "data = spark.read.csv(file_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 632211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct rows: 632211\n",
      "Number of duplicate rows: 0\n",
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- item_id: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Data Cleaning\n",
    "\n",
    "data = data.select(\n",
    "    col(\"User_A\").alias(\"user_id\"),\n",
    "    col(\"User_B\").alias(\"item_id\"),\n",
    "    col(\"Interaction_Intensity\").alias(\"rating\")\n",
    ")\n",
    "\n",
    "# Total rows in the dataset\n",
    "total_rows = data.count()\n",
    "print(f\"Total rows: {total_rows}\")\n",
    "\n",
    "# Count the number of distinct rows\n",
    "distinct_rows = data.dropDuplicates().count()\n",
    "print(f\"Distinct rows: {distinct_rows}\")\n",
    "\n",
    "# Calculate duplicates\n",
    "duplicates = total_rows - distinct_rows\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n",
    "\n",
    "\n",
    "data = data.orderBy(rand())\n",
    "\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+\n",
      "|user_id|item_id|rating|\n",
      "+-------+-------+------+\n",
      "|   1082|    875|   5.0|\n",
      "|    302|   1101|   4.0|\n",
      "|    343|    583|   2.0|\n",
      "|   1223|    100|   4.0|\n",
      "|    686|     85|   4.0|\n",
      "|   1099|   1259|   3.0|\n",
      "|    725|     50|   1.0|\n",
      "|    196|    888|   5.0|\n",
      "|    481|    716|   1.0|\n",
      "|   1114|    627|   2.0|\n",
      "+-------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View of the data\n",
    "data.limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data count: 569062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data count: 63127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Data Split\n",
    "\n",
    "train_data, test_data = data.randomSplit([0.9, 0.1], seed=42)\n",
    "# Verify split sizes\n",
    "print(f\"Training data count: {train_data.count()}\")\n",
    "print(f\"Test data count: {test_data.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/16 12:19:51 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/12/16 12:19:51 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "24/12/16 12:19:51 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    }
   ],
   "source": [
    "# Model Training\n",
    "\n",
    "\n",
    "\n",
    "# Initialize ALS model\n",
    "als = ALS(\n",
    "    #implicitPrefs=True,\n",
    "    maxIter=20,              # Number of iterations\n",
    "    regParam=0.1,            # Regularization parameter\n",
    "    rank=20,                 # Number of latent factors\n",
    "    userCol=\"user_id\",       # Column for user IDs\n",
    "    itemCol=\"item_id\",       # Column for item IDs\n",
    "    ratingCol=\"rating\",      # Column for ratings\n",
    "    coldStartStrategy=\"drop\" # Handle unseen users/items during predictions\n",
    ")\n",
    "\n",
    "# Fit the ALS model on the training data\n",
    "als_model = als.fit(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+----------+\n",
      "|user_id|item_id|rating|prediction|\n",
      "+-------+-------+------+----------+\n",
      "|      0|    362|   4.0|   2.95297|\n",
      "|      0|    491|   5.0| 3.0577862|\n",
      "|      1|    277|   5.0| 2.7910562|\n",
      "|      1|    500|   4.0| 3.0103023|\n",
      "|      1|    982|   3.0| 2.7162454|\n",
      "|      2|    317|   2.0| 3.0044632|\n",
      "|      2|    509|   3.0| 2.9574344|\n",
      "|      2|    572|   1.0| 2.9543889|\n",
      "|      2|    985|   5.0|  3.023848|\n",
      "|      3|    447|   1.0|  2.820734|\n",
      "|      3|    884|   3.0|  3.003873|\n",
      "|      3|   1296|   1.0|  2.833526|\n",
      "|      4|    170|   3.0|  3.015949|\n",
      "|      4|    914|   2.0| 2.8267546|\n",
      "|      5|    437|   1.0| 2.8948205|\n",
      "|      5|    791|   2.0| 2.7099829|\n",
      "|      6|    779|   4.0| 2.9317272|\n",
      "|      7|    139|   4.0|  2.889961|\n",
      "|      7|    193|   1.0|  2.733398|\n",
      "|      7|    265|   1.0| 2.7542136|\n",
      "+-------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions on the test set\n",
    "predictions = als_model.transform(test_data)\n",
    "\n",
    "# Show the predictions\n",
    "predictions.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rating prediction metrics: RMSE, MAE, explained variance, R-squared\n",
    "Ranking-based evaluation: MAP, NDCG, precision@K, recall@K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse : 1.3737048459668288 \n",
      " mae: 1.1881133907431838\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with RMSE and MAE\n",
    "\n",
    "evaluator_rmse = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "evaluator_mae = RegressionEvaluator(metricName=\"mae\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "\n",
    "rmse = evaluator_rmse.evaluate(predictions)\n",
    "mae = evaluator_mae.evaluate(predictions)\n",
    "print(f\"rmse : {rmse} \\n mae: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking Evaluation - Precision@K: 0.0038103076923076923, Recall@K: 0.3924662199622994\n"
     ]
    }
   ],
   "source": [
    "# Flatten Recommendations: Explode the nested recommendations to make it easier to evaluate: \n",
    "\n",
    "\n",
    "top_k_recommendations = als_model.recommendForAllUsers(500)\n",
    "\n",
    "\n",
    "top_k_recommendations = top_k_recommendations.withColumn(\"recommendation\", explode(col(\"recommendations\"))) \\\n",
    "    .select(\"user_id\", col(\"recommendation.item_id\").alias(\"item_id\"), col(\"recommendation.rating\").alias(\"prediction\"))\n",
    "\n",
    "# Join with Ground Truth\n",
    "joined = top_k_recommendations.join(test_data, on=[\"user_id\", \"item_id\"], how=\"inner\")\n",
    "\n",
    "# Precision@K and Recall@K\n",
    "precision_at_k = joined.count() / (top_k_recommendations.count() * 10)\n",
    "recall_at_k = joined.count() / test_data.count()\n",
    "\n",
    "print(f\"Ranking Evaluation - Precision@K: {precision_at_k}, Recall@K: {recall_at_k}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming we have obtained a good model after a deep model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+\n",
      "|user_id|item_id|prediction|\n",
      "+-------+-------+----------+\n",
      "|0      |100    |3.5692847 |\n",
      "|0      |840    |3.5431314 |\n",
      "|0      |1047   |3.48891   |\n",
      "|0      |901    |3.427322  |\n",
      "|0      |117    |3.3889112 |\n",
      "|0      |1258   |3.3825827 |\n",
      "|0      |874    |3.3819797 |\n",
      "|0      |436    |3.3791256 |\n",
      "|0      |832    |3.3397155 |\n",
      "|0      |701    |3.336751  |\n",
      "|0      |904    |3.3150492 |\n",
      "|0      |899    |3.298587  |\n",
      "|0      |818    |3.2930748 |\n",
      "|0      |58     |3.2900932 |\n",
      "|0      |938    |3.2883945 |\n",
      "|0      |15     |3.2758088 |\n",
      "|0      |29     |3.2718625 |\n",
      "|0      |525    |3.2670658 |\n",
      "|0      |656    |3.2640038 |\n",
      "|0      |1089   |3.2618954 |\n",
      "|0      |1071   |3.2614617 |\n",
      "|0      |422    |3.2583003 |\n",
      "|0      |407    |3.2581136 |\n",
      "|0      |1289   |3.252446  |\n",
      "|0      |992    |3.2519023 |\n",
      "|0      |934    |3.2493954 |\n",
      "|0      |64     |3.2349408 |\n",
      "|0      |876    |3.234303  |\n",
      "|0      |528    |3.2331333 |\n",
      "|0      |1295   |3.2298903 |\n",
      "|0      |668    |3.2295349 |\n",
      "|0      |56     |3.229528  |\n",
      "|0      |793    |3.2278342 |\n",
      "|0      |483    |3.2256298 |\n",
      "|0      |804    |3.225578  |\n",
      "|0      |342    |3.2238917 |\n",
      "|0      |834    |3.2205968 |\n",
      "|0      |660    |3.219499  |\n",
      "|0      |763    |3.2139301 |\n",
      "|0      |211    |3.2106133 |\n",
      "|0      |962    |3.2104409 |\n",
      "|0      |601    |3.204808  |\n",
      "|0      |1027   |3.2038536 |\n",
      "|0      |251    |3.2023222 |\n",
      "|0      |454    |3.201368  |\n",
      "|0      |1049   |3.199225  |\n",
      "|0      |1260   |3.199166  |\n",
      "|0      |250    |3.1968133 |\n",
      "|0      |616    |3.196243  |\n",
      "|0      |833    |3.1949935 |\n",
      "+-------+-------+----------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initial Recommendation Example of user 0\n",
    "top_k_recommendations.filter(col(\"user_id\").isin([0])).show(n=50, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Select Top-N Candidates for Content-Based Filtering (CBF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a window to rank predictions for each user\n",
    "window = Window.partitionBy(\"user_id\").orderBy(col(\"prediction\").desc())\n",
    "\n",
    "# Select top 200 candidates\n",
    "top_n_candidates = predictions.withColumn(\"rank\", row_number().over(window)) \\\n",
    "    .filter(col(\"rank\") <= 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+----------+----+\n",
      "|user_id|item_id|rating|prediction|rank|\n",
      "+-------+-------+------+----------+----+\n",
      "|      0|    904|   2.0| 3.3150492|   1|\n",
      "|      0|    763|   3.0| 3.2139301|   2|\n",
      "|      0|    601|   5.0|  3.204808|   3|\n",
      "|      0|   1031|   2.0| 3.1805916|   4|\n",
      "|      0|   1007|   2.0| 3.1190002|   5|\n",
      "|      0|    246|   4.0| 3.0943031|   6|\n",
      "|      0|    301|   3.0| 3.0645356|   7|\n",
      "|      0|    491|   5.0| 3.0577862|   8|\n",
      "|      0|   1015|   2.0| 3.0565495|   9|\n",
      "|      0|    240|   2.0|  3.039404|  10|\n",
      "|      0|    105|   4.0|  3.031528|  11|\n",
      "|      0|    292|   1.0| 3.0151675|  12|\n",
      "|      0|    766|   3.0| 3.0024548|  13|\n",
      "|      0|    622|   1.0| 2.9558887|  14|\n",
      "|      0|    362|   4.0|   2.95297|  15|\n",
      "|      0|    419|   5.0|   2.92155|  16|\n",
      "|      0|   1189|   2.0| 2.9207273|  17|\n",
      "|      0|   1127|   5.0|  2.902138|  18|\n",
      "|      0|    831|   5.0|  2.869922|  19|\n",
      "|      0|   1117|   5.0|   2.85972|  20|\n",
      "+-------+-------+------+----------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_n_candidates.limit(300).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
